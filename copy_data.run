#!/usr/local/bin/bash

# Folder to be used to download and process data
export MODEL_DATA_FOLDER="/tmp/cosmo-d2/"
export HOME_FOLDER=$(pwd)
export N_CONCUR_PROCESSES=4 
export NCFTP_BOOKMARK="altervista"
DATA_DOWNLOAD=true
DATA_PLOTTING=false
DATA_UPLOAD=false

##### LOAD functions to download model data
. ./functions_download_dwd.sh
export SHELL=$(type -p bash)
# We need to open many files at the same time
ulimit -Sn 4096
source ~/.bash_profile
# acivate our environment 
#conda activate nwp-py2
########################################### 

###########################################

mkdir -p ${MODEL_DATA_FOLDER}it
mkdir -p ${MODEL_DATA_FOLDER}nord

# Retrieve run ##########################
export year=`date +"%Y"`
export month=`date +"%m"`
export day=`date +"%d"`
export hour=`date +"%H"`
export hour_no_zero=`date -u +"%-H"`

if [ "$hour_no_zero" -ge 1 ] && [ "$hour_no_zero" -lt 4 ] 
then 
 run="00"
elif [ "$hour_no_zero" -ge 4 ] && [ "$hour_no_zero" -lt 7 ] 
then
 run="03"
elif [ "$hour_no_zero" -ge 7 ] && [ "$hour_no_zero" -lt 10 ] 
then
 run="06"
elif [ "$hour_no_zero" -ge 10 ] && [ "$hour_no_zero" -lt 13 ] 
then
 run="09"
elif [ "$hour_no_zero" -ge 13 ] && [ "$hour_no_zero" -lt 16 ] 
then
 run="12"
elif [ "$hour_no_zero" -ge 16 ] && [ "$hour_no_zero" -lt 19 ] 
then
 run="15"
elif [ "$hour_no_zero" -ge 19 ] && [ "$hour_no_zero" -lt 22 ] 
then
 run="18"
elif [ "$hour_no_zero" -ge 22 ] && [ "$hour_no_zero" -le 23 ] 
then
 run="21"
fi

export run

###########################################

# Move to the data folder to do processing
cd ${MODEL_DATA_FOLDER} || { echo 'Cannot change to DATA folder' ; exit 1; }

# SECTION 1 - DATA DOWNLOAD ############################################################

if [ "$DATA_DOWNLOAD" = true ]; then
	# Remove older files
	rm ${MODEL_DATA_FOLDER}*.nc
	rm ${MODEL_DATA_FOLDER}*.grib2

	# Invariant
	download_invariant_cosmo_d2

	#2-D variables
	# variables=("T_2M" "TD_2M" "U_10M" "V_10M" "PMSL" "CAPE_ML" "VMAX_10M" "TOT_PREC" \
	# "CLCL" "CLCH" "CLCT" "SNOWLMT" "HZEROCL" "H_SNOW" "SNOW_GSP"\
	# "RAIN_GSP" "TMAX_2M" "TMIN_2M" "WW" "DBZ_CMAX" "CIN_ML" "RELHUM_2M" )
	variables=("T_2M" "TD_2M" "U_10M" "V_10M" "PMSL" "CAPE_ML" "VMAX_10M" "TOT_PREC")
	parallel -j ${N_CONCUR_PROCESSES} --delay 1 download_merge_2d_variable_cosmo_d2 ::: "${variables[@]}"

	#3-D variables on pressure levels
	# variables=("T" "FI" "RELHUM" "U" "V")
	# parallel -j ${N_CONCUR_PROCESSES} --delay 2 download_merge_3d_variable_cosmo_d2 ::: "${variables[@]}"

fi 

############################################################


# SECTION 2 - DATA PLOTTING ############################################################

if [ "$DATA_PLOTTING" = true ]; then
	python --version
	cp ${HOME_FOLDER}/plotting/*.py ${MODEL_DATA_FOLDER}

	export QT_QPA_PLATFORM=offscreen # Needed to avoid errors when using Python without display

	python plot_meteogram.py Hamburg Pisa Milano Brocken Toulouse Utrecht

	scripts=("plot_cape.py" "plot_hsnow.py" "plot_pres_t2m_winds10m.py" "plot_rain_clouds.py" "plot_rain_acc.py"\
		     "plot_reflectivity.py" "plot_relhum.py" "plot_t.py" "plot_t850_pres.py" "plot_winds10m.py"\
		     "plot_winter.py" "plot_tmax.py")

	projections=("de" "it" "nord")

	parallel -j ${N_CONCUR_PROCESSES} python ::: "${scripts[@]}" ::: "${projections[@]}"
fi

############################################################

# SECTION 3 - IMAGES UPLOAD ############################################################
# Use ncftpbookmarks to add a new FTP server with credentials
if [ "$DATA_UPLOAD" = true ]; then
	# First upload meteograms
	ncftpput -R -v ${NCFTP_BOOKMARK} cosmo_de_forecasts/meteograms meteogram_*
	#
	# Then upload the other pictures
	#
	images_output=("cape_cin" "radar" "t850_pres" "t_v_pres" "winds10m" "precip_clouds"\
		"hsnow" "rh_500" "rh_700" "rh_850" "rh_950" "t_500" "t_700" "t_850" "t_950"\
		"winter" "precip_acc" "tmax")

	# suffix for naming
	projections_output=("" "it/" "nord/")
	# remote folder on server
	projections_output_folder=("cosmo_de_forecasts" "cosmo_de_forecasts/it" "cosmo_de_forecasts/nord")

	# Create a lisf of all the images to upload 
	upload_elements=()
	for i in "${!projections_output[@]}"; do
		for j in "${images_output[@]}"; do
			upload_elements+=("${projections_output_folder[$i]}/${j} ./${projections_output[$i]}${j}_*")
		done
	done

	# Finally upload the images 
	for k in "${upload_elements[@]}"; do
		ncftpput -R -v ${NCFTP_BOOKMARK} ${k}
	done

	# To be parallelized in the future if the FTP server accepts multiple connections
	# this doesn't work 
	# parallel -j 2 ncftpput -R -v ${NCFTP_BOOKMARK} ::: "${upload_elements[@]}"

fi 

# SECTION 4 - CLEANING ############################################################

#Remove images locally
rm ${MODEL_DATA_FOLDER}*.png
rm ${MODEL_DATA_FOLDER}nord/*.png
rm ${MODEL_DATA_FOLDER}it/*.png
rm ${MODEL_DATA_FOLDER}*.py

############################################################

cd -
